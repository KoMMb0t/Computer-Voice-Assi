{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¤ OpenWakeWord Training - \"Computer\" Wake-Word\n",
    "\n",
    "Dieses Notebook trainiert ein eigenes Wake-Word Modell mit OpenWakeWord.\n",
    "\n",
    "**Voraussetzungen:**\n",
    "- Aufnahmen auf Google Drive hochgeladen\n",
    "- Ordnerstruktur: `wake_word_recordings/positive`, `negative`, `background_noise`\n",
    "\n",
    "**Dauer:** 3-8 Stunden (je nach Anzahl der Samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Schritt 1: Google Drive verbinden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"âœ… Google Drive verbunden!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Schritt 2: OpenWakeWord installieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openwakeword tensorflow librosa soundfile\n",
    "print(\"âœ… OpenWakeWord installiert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Schritt 3: Pfade zu deinen Aufnahmen angeben\n",
    "\n",
    "**WICHTIG:** Passe die Pfade an, falls dein Ordner anders heiÃŸt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Pfade zu deinen Aufnahmen (ANPASSEN!)\n",
    "BASE_PATH = \"/content/drive/MyDrive/wake_word_recordings\"\n",
    "POSITIVE_PATH = os.path.join(BASE_PATH, \"positive\")\n",
    "NEGATIVE_PATH = os.path.join(BASE_PATH, \"negative\")\n",
    "BACKGROUND_PATH = os.path.join(BASE_PATH, \"background_noise\")\n",
    "\n",
    "# PrÃ¼fe ob Ordner existieren\n",
    "print(f\"Positive Samples: {len(os.listdir(POSITIVE_PATH))} Dateien\")\n",
    "print(f\"Negative Samples: {len(os.listdir(NEGATIVE_PATH))} Dateien\")\n",
    "print(f\"Background Noise: {len(os.listdir(BACKGROUND_PATH))} Dateien\")\n",
    "print(\"\\nâœ… Alle Ordner gefunden!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Schritt 4: Training vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Parameter\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 2  # Sekunden\n",
    "N_MELS = 40\n",
    "N_FFT = 512\n",
    "HOP_LENGTH = 160\n",
    "\n",
    "print(\"âœ… Training-Parameter gesetzt!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”Š Schritt 5: Audio-Dateien laden und vorverarbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path, duration=2, sr=16000):\n",
    "    \"\"\"LÃ¤dt Audio-Datei und normalisiert auf feste LÃ¤nge.\"\"\"\n",
    "    try:\n",
    "        audio, _ = librosa.load(file_path, sr=sr, duration=duration)\n",
    "        # Pad oder trim auf exakte LÃ¤nge\n",
    "        target_length = sr * duration\n",
    "        if len(audio) < target_length:\n",
    "            audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "        else:\n",
    "            audio = audio[:target_length]\n",
    "        return audio\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden von {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_melspectrogram(audio, sr=16000, n_mels=40, n_fft=512, hop_length=160):\n",
    "    \"\"\"Extrahiert Mel-Spektrogramm aus Audio.\"\"\"\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length\n",
    "    )\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "print(\"âœ… Audio-Funktionen definiert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Schritt 6: Dataset erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(positive_path, negative_path, background_path):\n",
    "    \"\"\"Erstellt Dataset aus Aufnahmen.\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Positive Samples (Label 1)\n",
    "    print(\"Lade positive Samples...\")\n",
    "    for i, filename in enumerate(os.listdir(positive_path)):\n",
    "        if filename.endswith('.wav'):\n",
    "            audio = load_audio(os.path.join(positive_path, filename))\n",
    "            if audio is not None:\n",
    "                mel_spec = extract_melspectrogram(audio)\n",
    "                X.append(mel_spec)\n",
    "                y.append(1)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  {i + 1} positive Samples geladen...\")\n",
    "    \n",
    "    # Negative Samples (Label 0)\n",
    "    print(\"Lade negative Samples...\")\n",
    "    for i, filename in enumerate(os.listdir(negative_path)):\n",
    "        if filename.endswith('.wav'):\n",
    "            audio = load_audio(os.path.join(negative_path, filename))\n",
    "            if audio is not None:\n",
    "                mel_spec = extract_melspectrogram(audio)\n",
    "                X.append(mel_spec)\n",
    "                y.append(0)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  {i + 1} negative Samples geladen...\")\n",
    "    \n",
    "    # Background Noise (Label 0)\n",
    "    print(\"Lade background noise...\")\n",
    "    for filename in os.listdir(background_path):\n",
    "        if filename.endswith('.wav'):\n",
    "            audio = load_audio(os.path.join(background_path, filename))\n",
    "            if audio is not None:\n",
    "                mel_spec = extract_melspectrogram(audio)\n",
    "                X.append(mel_spec)\n",
    "                y.append(0)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(f\"\\nâœ… Dataset erstellt!\")\n",
    "    print(f\"   Shape: {X.shape}\")\n",
    "    print(f\"   Positive: {np.sum(y == 1)}\")\n",
    "    print(f\"   Negative: {np.sum(y == 0)}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Dataset erstellen\n",
    "X, y = create_dataset(POSITIVE_PATH, NEGATIVE_PATH, BACKGROUND_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”€ Schritt 7: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape fÃ¼r CNN (Samples, Height, Width, Channels)\n",
    "X = X[..., np.newaxis]\n",
    "\n",
    "# Train/Test Split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"âœ… Dataset aufgeteilt!\")\n",
    "print(f\"   Training: {X_train.shape[0]} Samples\")\n",
    "print(f\"   Test: {X_test.shape[0]} Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Schritt 8: Modell erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \"\"\"Erstellt ein CNN-Modell fÃ¼r Wake-Word Detection.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Modell erstellen\n",
    "model = create_model(X_train.shape[1:])\n",
    "model.summary()\n",
    "\n",
    "print(\"\\nâœ… Modell erstellt!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Schritt 9: Training starten!\n",
    "\n",
    "**Das dauert jetzt 3-8 Stunden!** â³\n",
    "\n",
    "Du kannst das Fenster schlieÃŸen - das Training lÃ¤uft weiter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "# Training starten\n",
    "print(\"ðŸš€ Training startet...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Schritt 10: Ergebnisse anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nðŸ“Š Test Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"ðŸ“Š Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Schritt 11: Modell speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell auf Google Drive speichern\n",
    "model_path = \"/content/drive/MyDrive/computer_wake_word_model.h5\"\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"âœ… Modell gespeichert: {model_path}\")\n",
    "print(\"\\nðŸ“¥ Du kannst es jetzt von Google Drive herunterladen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ FERTIG!\n",
    "\n",
    "**Dein \"Computer\" Wake-Word Modell ist fertig!**\n",
    "\n",
    "**NÃ¤chste Schritte:**\n",
    "1. Lade `computer_wake_word_model.h5` von Google Drive herunter\n",
    "2. Kopiere es in dein Voice Assistant Projekt\n",
    "3. Integriere es in den Code\n",
    "4. Teste es!\n",
    "\n",
    "**Viel Erfolg!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "OpenWakeWord_Training_Computer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
