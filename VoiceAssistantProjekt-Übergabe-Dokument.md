# Voice Assistant Projekt - Ãœbergabe-Dokument

## ğŸ“‹ Projekt-Ãœbersicht

**Projektname:** Voice Assistant - KI Sprachsteuerung  
**GitHub Repository:** https://github.com/KoMMb0t/voice_assi  
**Aktueller Status:** FunktionsfÃ¤higer Prototyp mit Wake-Word-Doppelerkennungs-Problem  
**NÃ¤chster Schritt:** Eigenes "Computer" Wake-Word trainieren + LLM-Integration

---

## ğŸ¯ Was bisher erreicht wurde

### âœ… Erfolgreich implementiert:

1. **Voice Assistant Grundsystem**
   - Wake-Word Detection mit OpenWakeWord (aktuell: "hey jarvis")
   - Speech-to-Text mit Vosk (deutsches Modell)
   - Text-to-Speech mit Edge TTS (Stimme: Katja)
   - Voice Activity Detection (VAD) fÃ¼r automatische Aufnahme-Beendigung

2. **Befehle implementiert:**
   - Programme Ã¶ffnen (Taschenrechner, Notepad, Explorer, Firefox)
   - Webseiten Ã¶ffnen (YouTube, ChatGPT, Google, Gmail, GitHub, Wikipedia)
   - Datum & Uhrzeit (mit deutscher Ãœbersetzung)
   - HÃ¶flichkeits-Befehle ("Danke", "Abbrechen", "Nichts")
   - Hilfe-Befehl

3. **Projekt-Setup:**
   - Git Repository initialisiert
   - `.gitignore` erstellt (schlieÃŸt `.venv` aus)
   - `requirements.txt` generiert
   - README.md mit deutscher und englischer Dokumentation
   - Alles auf GitHub hochgeladen

4. **Benutzerfreundlichkeit:**
   - Batch-Datei zum Starten (`Start_Voice_Assistant.bat`)
   - Desktop-Icon mit eigenem Symbol
   - PowerShell-Alias geplant (noch nicht vollstÃ¤ndig implementiert)

### âŒ Aktuelles Problem:

**Wake-Word-Doppelerkennung:**
- Das Wake-Word "hey jarvis" wird manchmal doppelt erkannt, ohne dass der Nutzer es erneut sagt
- Score ist konstant sehr hoch (0.99-1.00)
- Verschiedene Fixes wurden versucht (Threshold senken, Cooldown verlÃ¤ngern, Audio-Buffer leeren)
- Problem besteht weiterhin

---

## ğŸš€ NÃ¤chste Schritte (Option 1)

### Hauptziel: Eigenes "Computer" Wake-Word trainieren

**Warum?**
- "Computer" ist das gewÃ¼nschte Wake-Word (wie in Star Trek)
- KÃ¶nnte das Doppelerkennungs-Problem lÃ¶sen
- Steht auf der Roadmap

**Schritte:**

1. **Aufnahmen sammeln**
   - 100-200 Aufnahmen von "Computer" in verschiedenen Tonlagen
   - HintergrundgerÃ¤usche aufnehmen
   - Negative Samples (andere WÃ¶rter)

2. **Modell trainieren**
   - OpenWakeWord Training-Pipeline nutzen
   - Oder: Porcupine Custom Wake Word (kostenpflichtig, aber einfacher)
   - Oder: Snowboy (veraltet, aber kostenlos)

3. **Modell integrieren**
   - In den bestehenden Code einbauen
   - Testen und optimieren

4. **Auf GitHub hochladen**
   - Neues Modell committen
   - README aktualisieren

---

## ğŸ¤– LLM-Integration (Roadmap)

### Ziel: Intelligente Konversationen statt nur Befehle

**Geplante LLM-Integrationen:**
- ChatGPT (OpenAI API)
- Perplexity (fÃ¼r Recherche)
- Monica (Browser-Extension)
- Manus (fÃ¼r komplexe Aufgaben)

**Architektur:**
1. Wake-Word erkannt â†’ "Ja?"
2. Nutzer spricht Befehl/Frage
3. **NEU:** Wenn kein Befehl erkannt â†’ An LLM senden
4. LLM antwortet â†’ TTS spricht Antwort

**Beispiel:**
- "Computer, wie wird das Wetter morgen?" â†’ Perplexity API
- "Computer, schreibe eine E-Mail an Max" â†’ ChatGPT
- "Computer, erstelle eine PrÃ¤sentation Ã¼ber KI" â†’ Manus

---

## ğŸ”§ Technische Details

### Projektstruktur:

```
C:\Users\ModBot\ki-sprachsteuerung\
â”œâ”€â”€ .venv/                          # Virtual Environment (nicht auf GitHub)
â”œâ”€â”€ .gitignore                      # Git-Ignore-Datei
â”œâ”€â”€ requirements.txt                # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ README.md                       # Projekt-Dokumentation
â”œâ”€â”€ voice_assistant_edge.py         # Hauptprogramm (aktuelle Version)
â”œâ”€â”€ voice_assistant_tts.py          # TTS-Test-Version
â”œâ”€â”€ listen.py                       # Wake-Word-Test
â”œâ”€â”€ listen_and_transcribe.py        # STT-Test
â”œâ”€â”€ download_models.py              # Modell-Downloader
â””â”€â”€ Start_Voice_Assistant.bat       # Batch-Datei zum Starten
```

### Wichtige Konfigurationen:

```python
WAKE_WORD = "hey jarvis"           # Soll zu "computer" werden
SAMPLE_RATE = 16000                # Audio-Sample-Rate
CHUNK_SAMPLES = 1280               # Audio-Chunk-GrÃ¶ÃŸe
SILENCE_TIMEOUT = 2.0              # Stille-Erkennung (Sekunden)
MAX_RECORD_TIME = 30               # Max. Aufnahmezeit (Sekunden)
TTS_VOICE = "de-DE-KatjaNeural"    # Edge TTS Stimme
```

### AbhÃ¤ngigkeiten (requirements.txt):

```
openwakeword
vosk
edge-tts
sounddevice
numpy
pygame
```

---

## ğŸ“ Bekannte Probleme & LÃ¶sungsansÃ¤tze

### Problem 1: Wake-Word-Doppelerkennung

**Versuchte LÃ¶sungen:**
- Threshold von 0.95 auf 0.7 gesenkt
- Cooldown von 0.5 auf 2.0 Sekunden erhÃ¶ht
- Audio-Buffer nach Wake-Word leeren
- Cooldown-Flag hinzugefÃ¼gt

**Noch nicht versucht:**
- Threshold auf 0.5 oder niedriger senken
- Cooldown auf 4+ Sekunden erhÃ¶hen
- Wake-Word-Listening wÃ¤hrend Befehlsverarbeitung komplett pausieren
- Anderes Wake-Word-Modell testen (z.B. "alexa" - aber nicht gewÃ¼nscht)

### Problem 2: Mikrofon-Empfindlichkeit

**LÃ¶sung:** Mikrofon-LautstÃ¤rke in Windows reduziert (bereits erledigt)

---

## ğŸ“ Manus-Features nutzen

### Parallele Aufgaben in Manus:

**Manus kann mehrere Aufgaben gleichzeitig bearbeiten!**

**Beispiel-Workflow:**

1. **Chat 1:** "Computer" Wake-Word trainieren
   - Aufnahmen machen
   - Modell trainieren
   - Testen

2. **Chat 2:** LLM-Integration vorbereiten
   - API-Keys besorgen
   - Code-Struktur planen
   - Erste Tests

3. **Chat 3:** GitHub-Dokumentation verbessern
   - README erweitern
   - Screenshots hinzufÃ¼gen
   - Roadmap aktualisieren

**So startest du parallele Aufgaben:**
- Ã–ffne mehrere Manus-Chats (neue Tabs)
- Gib jedem Chat eine spezifische Aufgabe
- Manus arbeitet an allen gleichzeitig

---

## ğŸ”— Wichtige Links

- **GitHub Repo:** https://github.com/KoMMb0t/voice_assi
- **OpenWakeWord Docs:** https://github.com/dscripka/openWakeWord
- **Vosk Models:** https://alphacephei.com/vosk/models
- **Edge TTS:** https://github.com/rany2/edge-tts

---

## ğŸ’¬ Ãœbergabe-Prompt fÃ¼r neuen Manus-Chat

**Kopiere diesen Text in einen neuen Manus-Chat:**

```
Hallo! Ich arbeite an einem Voice Assistant Projekt und brauche Hilfe beim nÃ¤chsten Schritt.

**Aktueller Stand:**
- FunktionsfÃ¤higer Voice Assistant mit Wake-Word ("hey jarvis"), STT (Vosk), TTS (Edge TTS)
- Projekt ist auf GitHub: https://github.com/KoMMb0t/voice_assi
- Problem: Wake-Word wird manchmal doppelt erkannt

**NÃ¤chstes Ziel:**
1. Eigenes "Computer" Wake-Word trainieren (Option 1)
2. LLM-Integration (ChatGPT, Perplexity, Monica, Manus)
3. Alles auf GitHub dokumentieren

**Technische Details:**
- Windows 11 Mini PC
- Python 3.11
- Virtual Environment: .venv
- Projektordner: C:\Users\ModBot\ki-sprachsteuerung

**Ich habe ein detailliertes Ãœbergabe-Dokument mit allen Informationen.**

Kannst du mir helfen, das "Computer" Wake-Word zu trainieren und die LLM-Integration zu planen?
```

---

## ğŸ“Š Roadmap (aus README.md)

- [ ] LLM integration for more intelligent conversations (ChatGPT, Perplexity, etc.)
- [ ] Expand to other devices (Jetson Nano, Raspberry Pi, Android)
- [ğŸ”„] Train a custom "Computer" wake word model (IN ARBEIT)
- [ ] Integrate with home automation systems
- [ ] Enable secure remote access (VPN/Tailscale)

---

## ğŸ¯ Erfolgs-Kriterien fÃ¼r Option 1

**Das "Computer" Wake-Word ist erfolgreich, wenn:**
1. âœ… ZuverlÃ¤ssige Erkennung (>95% Erfolgsquote)
2. âœ… Keine Doppel-Erkennungen
3. âœ… Keine Fehlerkennungen bei Ã¤hnlichen WÃ¶rtern
4. âœ… Funktioniert in verschiedenen Umgebungen (leise, laut, mit HintergrundgerÃ¤uschen)
5. âœ… Modell ist auf GitHub verfÃ¼gbar

---

## ğŸ¤ Zusammenarbeit mit anderen KIs

### ChatGPT:
- Code-Optimierung
- Algorithmen erklÃ¤ren
- Schnelle Antworten

### Perplexity:
- Recherche zu Wake-Word-Training
- Vergleich verschiedener AnsÃ¤tze
- Aktuelle Best Practices

### Monica:
- Browser-basierte Aufgaben
- Schnelle Web-Recherche

### Manus:
- Komplexe Projekte (wie dieses!)
- Parallele Aufgaben
- Langfristige Planung

---

## ğŸ“Œ Wichtige Notizen

- Nutzer heiÃŸt: ModBot / KoMMb0t (GitHub)
- E-Mail: kommuniverse@gmail.com
- Bevorzugte Sprache: Deutsch
- Erfahrung: AnfÃ¤nger in Python/Git, aber lernwillig
- Ziel: GerÃ¤teÃ¼bergreifende KI-Sprachsteuerung (Windows, Linux, Android)

---

**Viel Erfolg mit dem Projekt!** ğŸš€
